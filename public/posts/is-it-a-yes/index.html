<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>ML with a AWS DeepLens: Is it あ? Yes it is! | Drentin&#39;s Findings</title>
<meta name="keywords" content="aws, image-processing, amazon-web-services, iot, aws-lambda">
<meta name="description" content="Starting last week I felt like I was ready to jump into attempting to work off the knowledge I had built up doing the examples previously and attempt the main goal; to create a model that was capable of recognising some of the Japanese Hiragana character set.
Problem - Input Data! My initial problem that I had been playing with was the idea of a training data set - where would I get a good set of training data from?">
<meta name="author" content="">
<link rel="canonical" href="http://dev.drentin.id.au/posts/is-it-a-yes/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.48a18943c2fc15c38a372b8dde1f5e5dc0bc64fa6cb90f5a817d2f8c76b7f3ae.css" integrity="sha256-SKGJQ8L8FcOKNyuN3h9eXcC8ZPpsuQ9agX0vjHa3864=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.4dcb3c4f38462f66c6b6137227726f5543cb934cca9788f041c087e374491df2.js" integrity="sha256-Tcs8TzhGL2bGthNyJ3JvVUPLk0zKl4jwQcCH43RJHfI="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="http://dev.drentin.id.au/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://dev.drentin.id.au/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://dev.drentin.id.au/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://dev.drentin.id.au/apple-touch-icon.png">
<link rel="mask-icon" href="http://dev.drentin.id.au/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="ML with a AWS DeepLens: Is it あ? Yes it is!" />
<meta property="og:description" content="Starting last week I felt like I was ready to jump into attempting to work off the knowledge I had built up doing the examples previously and attempt the main goal; to create a model that was capable of recognising some of the Japanese Hiragana character set.
Problem - Input Data! My initial problem that I had been playing with was the idea of a training data set - where would I get a good set of training data from?" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://dev.drentin.id.au/posts/is-it-a-yes/" />
<meta property="og:image" content="http://dev.drentin.id.au/posts/is-it-a-yes/images/0.jpg" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-09-24T01:00:00&#43;10:00" />
<meta property="article:modified_time" content="2021-09-24T01:00:00&#43;10:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="http://dev.drentin.id.au/posts/is-it-a-yes/images/0.jpg" />
<meta name="twitter:title" content="ML with a AWS DeepLens: Is it あ? Yes it is!"/>
<meta name="twitter:description" content="Starting last week I felt like I was ready to jump into attempting to work off the knowledge I had built up doing the examples previously and attempt the main goal; to create a model that was capable of recognising some of the Japanese Hiragana character set.
Problem - Input Data! My initial problem that I had been playing with was the idea of a training data set - where would I get a good set of training data from?"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "http://dev.drentin.id.au/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "ML with a AWS DeepLens: Is it あ? Yes it is!",
      "item": "http://dev.drentin.id.au/posts/is-it-a-yes/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "ML with a AWS DeepLens: Is it あ? Yes it is!",
  "name": "ML with a AWS DeepLens: Is it あ? Yes it is!",
  "description": "Starting last week I felt like I was ready to jump into attempting to work off the knowledge I had built up doing the examples previously and attempt the main goal; to create a model that was capable of recognising some of the Japanese Hiragana character set.\nProblem - Input Data! My initial problem that I had been playing with was the idea of a training data set - where would I get a good set of training data from?",
  "keywords": [
    "aws", "image-processing", "amazon-web-services", "iot", "aws-lambda"
  ],
  "articleBody": "Starting last week I felt like I was ready to jump into attempting to work off the knowledge I had built up doing the examples previously and attempt the main goal; to create a model that was capable of recognising some of the Japanese Hiragana character set.\nProblem - Input Data! My initial problem that I had been playing with was the idea of a training data set - where would I get a good set of training data from?\nLuckily this was no where near as significant a problem as I had perceived it to be. The ETL Character Database is database of 1.2 billion characters - numerals, symbols, alphabetic and… Japanese characters! The database I needed access to was the eighth database, ETL-8, which contained many written examples of the hiragana character set.\nI was concentrating on the first 5 characters of the Hiragana character set - あいうえお, or rather A I U E O. You may recognise these as they are there the exact same set of characters we use in English as vowels, just in a different order. These characters presented a good challenge as there are similar looking characters in the mix, like う/U and え/E. These look somewhat similar, similar enough it could confuse a trained model… potentially.\nIn total this dataset provided me with 160 images per character, so a total of 800 images - an amazing dataset for something I previously had no idea how to solve!\nSolution - Train the model! With my input dataset issues solved I set off to train a model to use this dataset.\nInitially I was going to search for the most appropriate model to use and research if there were character-orientated recognition models already out there but then the idea hit me - characters like hiragana are drawings essentially. Why not just use the model from the Building a Pictionary-style game with AWS DeepLens example I did previously and change the training dataset?\nSo instead of going for all out perfection first round I did just the above. I created a new Jupyter notebook, transferred the required parts over to this new notebook and after failing multiple times due to menial syntactical mistakes I reach the point of testing the model I had created - with good results!\nThe excluded testing dataset passed with very high confidence! Things were looking great so far.\nThe real test has arrived - will a AWS DeeLens deployed model work as well as it did in testing? Deploying a functioning Lambda function to work with the AWS IoT output the AWS DeepLens was producing proved difficult beyond logic and is still unsolved - for some reason I cannot get any function that is using Python 3 (in particular the supported Python 3.7) to work. More on this another day, however long story short I reverted back to using Python 2.7 and strived to move forward with my depreciated runtime!\nI printed out a computer-generated set of A I U E O to post up on my wall to test my model. Below are the results;\nFor a model trained with a pretty vanilla setup these are impressive results! Admittedly the above results are for perfectly shaped computer-generated characters.\nWhen I use my own human-written characters the results are not as amazing. Still correct, but with a much lower level of confidence;\nNext Steps! Whilst this was a successful attempt and I’m happy with the results many improvements could be made;\n All ELT Database character data is scanned from paper and is therefore presented facing straight at the character, so to speak. It’s like we’re looking straight forward at the characters. This bias presents itself when using the AWS DeepLens - predictions are great when the camera is faced directly towards the character in question. When the camera moves slightly to the left or right however accuracy falls off quickly. Discovering how to overcome this weakness in my dataset will be interesting! I am currently using the same model as the Pictionary example; a image classification model. I am still wondering if there’s a more appropriate model out there. Python 3 is the bane of my existence when using the AWS DeepLens. Will I be able to overcome the compatibility issues? Time will tell!  ",
  "wordCount" : "714",
  "inLanguage": "en",
  "image":"http://dev.drentin.id.au/posts/is-it-a-yes/images/0.jpg","datePublished": "2021-09-24T01:00:00+10:00",
  "dateModified": "2021-09-24T01:00:00+10:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://dev.drentin.id.au/posts/is-it-a-yes/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Drentin's Findings",
    "logo": {
      "@type": "ImageObject",
      "url": "http://dev.drentin.id.au/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://dev.drentin.id.au/" accesskey="h" title="Drentin&#39;s Findings (Alt + H)">Drentin&#39;s Findings</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="http://dev.drentin.id.au/posts/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="http://dev.drentin.id.au/archives/" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="http://dev.drentin.id.au/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="http://dev.drentin.id.au/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://dev.drentin.id.au/">Home</a>&nbsp;»&nbsp;<a href="http://dev.drentin.id.au/posts/">Posts</a></div>
    <h1 class="post-title">
      ML with a AWS DeepLens: Is it あ? Yes it is!
    </h1>
    <div class="post-meta"><span title='2021-09-24 01:00:00 +1000 AEST'>September 24, 2021</span>&nbsp;·&nbsp;4 min&nbsp;|&nbsp;<a href="https://github.com/drentinsfindings/content/posts/is-it-a-yes/index.md" rel="noopener noreferrer" target="_blank">Suggest Changes</a>

</div>
  </header> 
<figure class="entry-cover">
        <img loading="lazy" srcset="http://dev.drentin.id.au/posts/is-it-a-yes/images/0_huc60faf935cc95af5ca53dc00c8bb00dd_46563_360x0_resize_q75_box.jpg 360w ,http://dev.drentin.id.au/posts/is-it-a-yes/images/0_huc60faf935cc95af5ca53dc00c8bb00dd_46563_480x0_resize_q75_box.jpg 480w ,http://dev.drentin.id.au/posts/is-it-a-yes/images/0_huc60faf935cc95af5ca53dc00c8bb00dd_46563_720x0_resize_q75_box.jpg 720w ,http://dev.drentin.id.au/posts/is-it-a-yes/images/0_huc60faf935cc95af5ca53dc00c8bb00dd_46563_1080x0_resize_q75_box.jpg 1080w ,http://dev.drentin.id.au/posts/is-it-a-yes/images/0_huc60faf935cc95af5ca53dc00c8bb00dd_46563_1500x0_resize_q75_box.jpg 1500w ,http://dev.drentin.id.au/posts/is-it-a-yes/images/0.jpg 1600w" 
            sizes="(min-width: 768px) 720px, 100vw" src="http://dev.drentin.id.au/posts/is-it-a-yes/images/0.jpg" alt="Using a Image Classification Model to detect the first 5 Japanese Hiragana characters" 
            width="1600" height="840">
        <p>Using a Image Classification Model to detect the first 5 Japanese Hiragana characters</p>
</figure><div class="toc">
    <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#problem---input-data" aria-label="Problem - Input Data!">Problem - Input Data!</a></li>
                <li>
                    <a href="#solution---train-the-model" aria-label="Solution - Train the model!">Solution - Train the model!</a></li>
                <li>
                    <a href="#the-real-test-has-arrived---will-a-aws-deelens-deployed-model-work-as-well-as-it-did-in-testing" aria-label="The real test has arrived - will a AWS DeeLens deployed model work as well as it did in testing?">The real test has arrived - will a AWS DeeLens deployed model work as well as it did in testing?</a></li>
                <li>
                    <a href="#next-steps" aria-label="Next Steps!">Next Steps!</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>Starting last week I felt like I was ready to jump into attempting to work off the knowledge I had built up doing the examples previously and attempt the main goal; to create a model that was capable of recognising some of the Japanese Hiragana character set.</p>
<h1 id="problem---input-data">Problem - Input Data!<a hidden class="anchor" aria-hidden="true" href="#problem---input-data">#</a></h1>
<p>My initial problem that I had been playing with was the idea of a training data set - where would I get a good set of training data from?</p>
<p>Luckily this was no where near as significant a problem as I had perceived it to be. The  <a href="http://etlcdb.db.aist.go.jp/">ETL Character Database</a> is database of 1.2 billion characters - numerals, symbols, alphabetic and&hellip; Japanese characters! The database I needed access to was the eighth database, ETL-8, which contained many written examples of the hiragana character set.</p>
<p>I was concentrating on the first 5 characters of the Hiragana character set - あいうえお, or rather A I U E O. You may recognise these as they are there the exact same set of characters we use in English as vowels, just in a different order.
These characters presented a good challenge as there are similar looking characters in the mix, like う/U and え/E. These look somewhat similar, similar enough it could confuse a trained model&hellip; potentially.</p>
<p>In total this dataset provided me with 160 images per character, so a total of 800 images - an amazing dataset for something I previously had no idea how to solve!</p>
<p><img loading="lazy" src="images/1.jpg" alt="1.jpg"  />
</p>
<h1 id="solution---train-the-model">Solution - Train the model!<a hidden class="anchor" aria-hidden="true" href="#solution---train-the-model">#</a></h1>
<p>With my input dataset issues solved I set off to train a model to use this dataset.</p>
<p>Initially I was going to search for the most appropriate model to use and research if there were character-orientated recognition models already out there but then the idea hit me - characters like hiragana are drawings essentially. Why not just use the model from the <a href="https://www.awsdeeplens.recipes/300_intermediate/330_guess_drawing/">Building a Pictionary-style game with AWS DeepLens</a> example I did previously and change the training dataset?</p>
<p>So instead of going for all out perfection first round I did just the above. I created a new Jupyter notebook, transferred the required parts over to this new notebook and after failing multiple times due to menial syntactical mistakes I reach the point of testing the model I had created - with good results!</p>
<p>The excluded testing dataset passed with very high confidence! Things were looking great so far.</p>
<h1 id="the-real-test-has-arrived---will-a-aws-deelens-deployed-model-work-as-well-as-it-did-in-testing">The real test has arrived - will a AWS DeeLens deployed model work as well as it did in testing?<a hidden class="anchor" aria-hidden="true" href="#the-real-test-has-arrived---will-a-aws-deelens-deployed-model-work-as-well-as-it-did-in-testing">#</a></h1>
<p>Deploying a functioning Lambda function to work with the AWS IoT output the AWS DeepLens was producing proved difficult beyond logic and is still unsolved - for some reason I cannot get any function that is using Python 3 (in particular the supported Python 3.7) to work. More on this another day, however long story short I reverted back to using Python 2.7 and strived to move forward with my depreciated runtime!</p>
<p>I printed out a computer-generated set of A I U E O to post up on my wall to test my model. Below are the results;</p>
<p><img loading="lazy" src="images/2.jpg" alt="2.jpg"  />
</p>
<p>For a model trained with a pretty vanilla setup these are impressive results!
Admittedly the above results are for perfectly shaped computer-generated characters.</p>
<p>When I use my own human-written characters the results are not as amazing. Still correct, but with a much lower level of confidence;</p>
<p><img loading="lazy" src="images/3.jpg" alt="3.jpg"  />
</p>
<h1 id="next-steps">Next Steps!<a hidden class="anchor" aria-hidden="true" href="#next-steps">#</a></h1>
<p>Whilst this was a successful attempt and I&rsquo;m happy with the results many improvements could be made;</p>
<ol>
<li>All ELT Database character data is scanned from paper and is therefore presented facing straight at the character, so to speak. It&rsquo;s like we&rsquo;re looking straight forward at the characters. This bias presents itself when using the AWS DeepLens - predictions are great when the camera is faced directly towards the character in question. When the camera moves slightly to the left or right however accuracy falls off quickly.
Discovering how to overcome this weakness in my dataset will be interesting!</li>
<li>I am currently using the same model as the Pictionary example; a image classification model. I am still wondering if there&rsquo;s a more appropriate model out there.</li>
<li>Python 3 is the bane of my existence when using the AWS DeepLens. Will I be able to overcome the compatibility issues? Time will tell!</li>
</ol>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://dev.drentin.id.au/tags/aws/">aws</a></li>
      <li><a href="http://dev.drentin.id.au/tags/image-processing/">image-processing</a></li>
      <li><a href="http://dev.drentin.id.au/tags/amazon-web-services/">amazon-web-services</a></li>
      <li><a href="http://dev.drentin.id.au/tags/iot/">iot</a></li>
      <li><a href="http://dev.drentin.id.au/tags/aws-lambda/">aws-lambda</a></li>
    </ul>
<nav class="paginav">
  <a class="next" href="http://dev.drentin.id.au/posts/compost-landfill-recycling/">
    <span class="title">Next Page »</span>
    <br>
    <span>ML with a AWS DeepLens: Compost, Landfill or Recycling..?</span>
  </a>
</nav>


<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share ML with a AWS DeepLens: Is it あ? Yes it is! on twitter"
        href="https://twitter.com/intent/tweet/?text=ML%20with%20a%20AWS%20DeepLens%3a%20Is%20it%20%e3%81%82%3f%20Yes%20it%20is%21&amp;url=http%3a%2f%2fdev.drentin.id.au%2fposts%2fis-it-a-yes%2f&amp;hashtags=aws%2cimage-processing%2camazon-web-services%2ciot%2caws-lambda">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share ML with a AWS DeepLens: Is it あ? Yes it is! on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2fdev.drentin.id.au%2fposts%2fis-it-a-yes%2f&amp;title=ML%20with%20a%20AWS%20DeepLens%3a%20Is%20it%20%e3%81%82%3f%20Yes%20it%20is%21&amp;summary=ML%20with%20a%20AWS%20DeepLens%3a%20Is%20it%20%e3%81%82%3f%20Yes%20it%20is%21&amp;source=http%3a%2f%2fdev.drentin.id.au%2fposts%2fis-it-a-yes%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share ML with a AWS DeepLens: Is it あ? Yes it is! on reddit"
        href="https://reddit.com/submit?url=http%3a%2f%2fdev.drentin.id.au%2fposts%2fis-it-a-yes%2f&title=ML%20with%20a%20AWS%20DeepLens%3a%20Is%20it%20%e3%81%82%3f%20Yes%20it%20is%21">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share ML with a AWS DeepLens: Is it あ? Yes it is! on facebook"
        href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2fdev.drentin.id.au%2fposts%2fis-it-a-yes%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share ML with a AWS DeepLens: Is it あ? Yes it is! on whatsapp"
        href="https://api.whatsapp.com/send?text=ML%20with%20a%20AWS%20DeepLens%3a%20Is%20it%20%e3%81%82%3f%20Yes%20it%20is%21%20-%20http%3a%2f%2fdev.drentin.id.au%2fposts%2fis-it-a-yes%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share ML with a AWS DeepLens: Is it あ? Yes it is! on telegram"
        href="https://telegram.me/share/url?text=ML%20with%20a%20AWS%20DeepLens%3a%20Is%20it%20%e3%81%82%3f%20Yes%20it%20is%21&amp;url=http%3a%2f%2fdev.drentin.id.au%2fposts%2fis-it-a-yes%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
</div>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2022 <a href="http://dev.drentin.id.au/">Drentin&#39;s Findings</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
